{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10424cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'dalle2_pytorch.py': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!mv dalle2_pytorch.py /home/user/conda/envs/iivii/lib/python3.10/site-packages/dalle2_pytorch/dalle2_pytorch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ec0b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dalle2_laion import ModelLoadConfig, DalleModelManager\n",
    "from dalle2_laion.scripts import InferenceScript\n",
    "\n",
    "class ExampleInference(InferenceScript):\n",
    "    def run(self, text: str):\n",
    "        \"\"\"\n",
    "        Takes a string and returns a single image.\n",
    "        \"\"\"\n",
    "        text = [text]\n",
    "        image_embedding_map = self._sample_prior(text)\n",
    "        image_embedding = image_embedding_map[0][0].unsqueeze(0)\n",
    "        image_map = self._sample_decoder(text=text, image_embed=image_embedding)\n",
    "        return image_map[0][0]\n",
    "\n",
    "# model_config = ModelLoadConfig.from_json_path(\"dalle2_laion.json\")\n",
    "# model_manager = DalleModelManager(model_config)\n",
    "# inference = ExampleInference(model_manager)\n",
    "# image = inference.run(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c5904b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelLoadConfig.from_json_path(\"dalle2_laion.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec8cb59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This decoder was trained on version 1.1.0 but the current version is 1.2.1. This may result in the model failing to load.\n",
      "FIX: Switch to this version with `pip install DALLE2-pytorch==1.1.0`. If different models suggest different versions, you may just need to choose one.\n",
      "WARNING: This decoder was trained on an old version of Dalle2. This may result in the model failing to load or it may lead to producing garbage results.\n",
      "WARNING: This prior was trained on an old version of Dalle2. This may result in the model failing to load or it may produce garbage results.\n"
     ]
    }
   ],
   "source": [
    "model_manager = DalleModelManager(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1795302",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = ExampleInference(model_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb06f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from torchvision.transforms import Compose, ToTensor, Pad, Resize, ToPILImage, InterpolationMode\n",
    "\n",
    "class CocoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, im_dir, caption_dir):\n",
    "        self.im_dir = im_dir\n",
    "        self.caption_dir = caption_dir\n",
    "        self.im_fnames = sorted(os.listdir(im_dir))\n",
    "        self.caption_fnames = sorted(os.listdir(caption_dir))\n",
    "        self.to_tensor_transform = ToTensor()\n",
    "        self.pad_transform = lambda im, pad_right, pad_bottom: Pad(padding=(0, 0, pad_right, pad_bottom))(im)\n",
    "        self.resize_transform = Resize((256, 256), interpolation=InterpolationMode.BILINEAR)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        im = Image.open(os.path.join(self.im_dir, self.im_fnames[idx]))\n",
    "        w, h = im.size\n",
    "        im = self.to_tensor_transform(im)\n",
    "        new_size = max(w, h)\n",
    "        im = self.pad_transform(im, new_size - w, new_size - h)\n",
    "        im = self.resize_transform(im)\n",
    "\n",
    "        with open(os.path.join(self.caption_dir, self.caption_fnames[idx]), 'r') as captions_f:\n",
    "            captions = captions_f.readlines()\n",
    "\n",
    "        return self.im_fnames[idx], im, captions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8a62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial, wraps\n",
    "from tqdm.auto import tqdm\n",
    "from contextlib import contextmanager\n",
    "from dalle2_pytorch.vqgan_vae import NullVQGanVAE, VQGanVAE\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def first(arr, d = None):\n",
    "    if len(arr) == 0:\n",
    "        return d\n",
    "    return arr[0]\n",
    "\n",
    "def maybe(fn):\n",
    "    @wraps(fn)\n",
    "    def inner(x, *args, **kwargs):\n",
    "        if not exists(x):\n",
    "            return x\n",
    "        return fn(x, *args, **kwargs)\n",
    "    return inner\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d\n",
    "\n",
    "def cast_tuple(val, length = None, validate = True):\n",
    "    if isinstance(val, list):\n",
    "        val = tuple(val)\n",
    "\n",
    "    out = val if isinstance(val, tuple) else ((val,) * default(length, 1))\n",
    "\n",
    "    if exists(length) and validate:\n",
    "        assert len(out) == length\n",
    "\n",
    "    return out\n",
    "\n",
    "@contextmanager\n",
    "def null_context(*args, **kwargs):\n",
    "    yield\n",
    "\n",
    "def eval_decorator(fn):\n",
    "    def inner(model, *args, **kwargs):\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "        out = fn(model, *args, **kwargs)\n",
    "        model.train(was_training)\n",
    "        return out\n",
    "    return inner\n",
    "\n",
    "def resize_image_to(\n",
    "    image,\n",
    "    target_image_size,\n",
    "    clamp_range = None,\n",
    "    nearest = False,\n",
    "    **kwargs\n",
    "):\n",
    "    orig_image_size = image.shape[-1]\n",
    "\n",
    "    if orig_image_size == target_image_size:\n",
    "        return image\n",
    "\n",
    "    if not nearest:\n",
    "        scale_factors = target_image_size / orig_image_size\n",
    "        out = resize(image, scale_factors = scale_factors, **kwargs)\n",
    "    else:\n",
    "        out = F.interpolate(image, target_image_size, mode = 'nearest')\n",
    "\n",
    "    if exists(clamp_range):\n",
    "        out = out.clamp(*clamp_range)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae3a95d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (unets): ModuleList(\n",
       "    (0): Unet(\n",
       "      (init_conv): CrossEmbedLayer(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(3, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(3, 80, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (2): Conv2d(3, 80, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7))\n",
       "        )\n",
       "      )\n",
       "      (to_time_hiddens): Sequential(\n",
       "        (0): SinusoidalPosEmb()\n",
       "        (1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (to_time_tokens): Sequential(\n",
       "        (0): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "        (1): Rearrange('b (r d) -> b r d', r=2)\n",
       "      )\n",
       "      (to_time_cond): Sequential(\n",
       "        (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (image_to_tokens): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=2048, bias=True)\n",
       "        (1): Rearrange('b (n d) -> b n d', n=4)\n",
       "      )\n",
       "      (to_image_hiddens): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=1280, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "      )\n",
       "      (norm_cond): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_mid_cond): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (text_to_cond): Linear(in_features=768, out_features=512, bias=True)\n",
       "      (init_resnet_block): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (project): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (project): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Conv2d(320, 320, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Residual(\n",
       "            (fn): LinearAttention(\n",
       "              (norm): ChanLayerNorm()\n",
       "              (nonlin): GELU(approximate='none')\n",
       "              (to_qkv): Conv2d(320, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(512, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): ChanLayerNorm()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Conv2d(320, 640, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=640, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=640, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): EinopsToAndFrom(\n",
       "            (fn): Residual(\n",
       "              (fn): Attention(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=640, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=640, out_features=128, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=640, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): Conv2d(640, 960, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1920, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1920, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=960, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=960, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): EinopsToAndFrom(\n",
       "            (fn): Residual(\n",
       "              (fn): Attention(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=960, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=960, out_features=128, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=960, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Conv2d(960, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): Conv2d(960, 1280, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=1280, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): EinopsToAndFrom(\n",
       "            (fn): Residual(\n",
       "              (fn): Attention(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=1280, out_features=128, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=1280, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "            )\n",
       "            (cross_attn): EinopsToAndFrom(\n",
       "              (fn): CrossAttention(\n",
       "                (norm): LayerNorm()\n",
       "                (norm_context): Identity()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=1280, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=1280, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): EinopsToAndFrom(\n",
       "            (fn): Residual(\n",
       "              (fn): Attention(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=1280, out_features=128, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=1280, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(1280, 3840, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1920, bias=True)\n",
       "            )\n",
       "            (cross_attn): EinopsToAndFrom(\n",
       "              (fn): CrossAttention(\n",
       "                (norm): LayerNorm()\n",
       "                (norm_context): Identity()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=960, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=960, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(1920, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(1920, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1920, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=960, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=960, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(1920, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Conv2d(1920, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): EinopsToAndFrom(\n",
       "            (fn): Residual(\n",
       "              (fn): Attention(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=960, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=960, out_features=128, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=960, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(960, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            )\n",
       "            (cross_attn): EinopsToAndFrom(\n",
       "              (fn): CrossAttention(\n",
       "                (norm): LayerNorm()\n",
       "                (norm_context): Identity()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=640, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=640, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=640, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=640, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): EinopsToAndFrom(\n",
       "            (fn): Residual(\n",
       "              (fn): Attention(\n",
       "                (norm): LayerNorm()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=640, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=640, out_features=128, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=640, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): Residual(\n",
       "            (fn): LinearAttention(\n",
       "              (norm): ChanLayerNorm()\n",
       "              (nonlin): GELU(approximate='none')\n",
       "              (to_qkv): Conv2d(320, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Conv2d(512, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): ChanLayerNorm()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "        )\n",
       "        (cross_attn): EinopsToAndFrom(\n",
       "          (fn): CrossAttention(\n",
       "            (norm): LayerNorm()\n",
       "            (norm_context): Identity()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=1280, bias=False)\n",
       "              (1): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): EinopsToAndFrom(\n",
       "        (fn): Residual(\n",
       "          (fn): Attention(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=1280, out_features=128, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=1280, bias=False)\n",
       "              (1): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=2560, bias=True)\n",
       "        )\n",
       "        (cross_attn): EinopsToAndFrom(\n",
       "          (fn): CrossAttention(\n",
       "            (norm): LayerNorm()\n",
       "            (norm_context): Identity()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=1280, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=1280, bias=False)\n",
       "              (1): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (project): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (upsample_combiner): UpsampleCombiner()\n",
       "      (final_resnet_block): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (project): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (project): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (to_out): Conv2d(320, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): Unet(\n",
       "      (init_conv): Conv2d(6, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (to_time_hiddens): Sequential(\n",
       "        (0): SinusoidalPosEmb()\n",
       "        (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (to_time_tokens): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (1): Rearrange('b (r d) -> b r d', r=2)\n",
       "      )\n",
       "      (to_time_cond): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (image_to_tokens): Identity()\n",
       "      (norm_cond): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_mid_cond): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (text_to_cond): Linear(in_features=768, out_features=512, bias=True)\n",
       "      (init_resnet_block): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Identity()\n",
       "          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Identity()\n",
       "          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): Conv2d(512, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1024, out_features=1536, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 768, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 768, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1024, out_features=1536, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=768, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 768, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 768, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Identity()\n",
       "          (4): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): Conv2d(768, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Identity()\n",
       "          (4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "            )\n",
       "            (cross_attn): EinopsToAndFrom(\n",
       "              (fn): CrossAttention(\n",
       "                (norm): LayerNorm()\n",
       "                (norm_context): Identity()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(1024, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1024, out_features=1536, bias=True)\n",
       "            )\n",
       "            (cross_attn): EinopsToAndFrom(\n",
       "              (fn): CrossAttention(\n",
       "                (norm): LayerNorm()\n",
       "                (norm_context): Identity()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=768, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 768, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 768, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1024, out_features=1536, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=768, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=768, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 768, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 768, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(768, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (cross_attn): EinopsToAndFrom(\n",
       "              (fn): CrossAttention(\n",
       "                (norm): LayerNorm()\n",
       "                (norm_context): Identity()\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "                  (1): LayerNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (cross_attn): EinopsToAndFrom(\n",
       "                (fn): CrossAttention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (norm_context): Identity()\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (project): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "            (res_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0-3): 4 x ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (project): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "                (act): SiLU()\n",
       "              )\n",
       "              (res_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "        )\n",
       "        (cross_attn): EinopsToAndFrom(\n",
       "          (fn): CrossAttention(\n",
       "            (norm): LayerNorm()\n",
       "            (norm_context): Identity()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (1): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): EinopsToAndFrom(\n",
       "        (fn): Residual(\n",
       "          (fn): Attention(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=1024, out_features=128, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (1): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "        )\n",
       "        (cross_attn): EinopsToAndFrom(\n",
       "          (fn): CrossAttention(\n",
       "            (norm): LayerNorm()\n",
       "            (norm_context): Identity()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (1): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (project): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (upsample_combiner): UpsampleCombiner()\n",
       "      (final_resnet_block): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (project): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (res_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (to_out): Conv2d(259, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (vaes): ModuleList(\n",
       "    (0-1): 2 x NullVQGanVAE()\n",
       "  )\n",
       "  (noise_schedulers): ModuleList(\n",
       "    (0-1): 2 x NoiseScheduler()\n",
       "  )\n",
       "  (lowres_conds): ModuleList(\n",
       "    (0): None\n",
       "    (1): LowresConditioner()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.model_manager.decoder_info.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e983c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample(\n",
    "    self,\n",
    "    lowres_cond_img=None,\n",
    "    image = None,\n",
    "    image_embed = None,\n",
    "    text = None,\n",
    "    text_encodings = None,\n",
    "    batch_size = 1,\n",
    "    cond_scale = 1.,\n",
    "    start_at_unet_number = 1,\n",
    "    stop_at_unet_number = None,\n",
    "    distributed = False,\n",
    "    inpaint_image = None,\n",
    "    inpaint_mask = None,\n",
    "    inpaint_resample_times = 5,\n",
    "):\n",
    "    assert self.unconditional or exists(image_embed), 'image embed must be present on sampling from decoder unless if trained unconditionally'\n",
    "\n",
    "    if not self.unconditional:\n",
    "        batch_size = image_embed.shape[0]\n",
    "\n",
    "    if exists(text) and not exists(text_encodings) and not self.unconditional:\n",
    "        assert exists(self.clip)\n",
    "        _, text_encodings = self.clip.embed_text(text)\n",
    "\n",
    "    assert not (self.condition_on_text_encodings and not exists(text_encodings)), 'text or text encodings must be passed into decoder if specified'\n",
    "    assert not (not self.condition_on_text_encodings and exists(text_encodings)), 'decoder specified not to be conditioned on text, yet it is presented'\n",
    "\n",
    "    assert not (exists(inpaint_image) ^ exists(inpaint_mask)), 'inpaint_image and inpaint_mask (boolean mask of [batch, height, width]) must be both given for inpainting'\n",
    "\n",
    "    img = None\n",
    "    if start_at_unet_number > 1:\n",
    "        # Then we are not generating the first image and one must have been passed in\n",
    "        assert exists(image), 'image must be passed in if starting at unet number > 1'\n",
    "        assert image.shape[0] == batch_size, 'image must have batch size of {} if starting at unet number > 1'.format(batch_size)\n",
    "        prev_unet_output_size = self.image_sizes[start_at_unet_number - 2]\n",
    "        img = resize_image_to(image, prev_unet_output_size, nearest = True)\n",
    "    is_cuda = next(self.parameters()).is_cuda\n",
    "    num_unets = self.num_unets\n",
    "    cond_scale = cast_tuple(cond_scale, num_unets)\n",
    "\n",
    "    for unet_number, unet, vae, channel, image_size, predict_x_start, learned_variance, noise_scheduler, lowres_cond, sample_timesteps, unet_cond_scale in tqdm(zip(range(1, num_unets + 1), self.unets, self.vaes, self.sample_channels, self.image_sizes, self.predict_x_start, self.learned_variance, self.noise_schedulers, self.lowres_conds, self.sample_timesteps, cond_scale)):\n",
    "        if unet_number < start_at_unet_number:\n",
    "            continue  # It's the easiest way to do it\n",
    "\n",
    "        context = self.one_unet_in_gpu(unet = unet) if is_cuda else null_context()\n",
    "\n",
    "        with context:\n",
    "            # prepare low resolution conditioning for upsamplers\n",
    "\n",
    "            #lowres_cond_img = lowres_noise_level = None\n",
    "            lowres_noise_level = None\n",
    "            shape = (batch_size, channel, image_size, image_size)\n",
    "\n",
    "#             if unet.lowres_cond:\n",
    "#                 lowres_cond_img = resize_image_to(img, target_image_size = image_size, clamp_range = self.input_image_range, nearest = True)\n",
    "\n",
    "#                 if lowres_cond.use_noise:\n",
    "#                     lowres_noise_level = torch.full((batch_size,), int(self.lowres_noise_sample_level * 1000), dtype = torch.long, device = self.device)\n",
    "#                     lowres_cond_img, _ = lowres_cond.noise_image(lowres_cond_img, lowres_noise_level)\n",
    "\n",
    "            # latent diffusion\n",
    "\n",
    "            is_latent_diffusion = isinstance(vae, VQGanVAE)\n",
    "            image_size = vae.get_encoded_fmap_size(image_size)\n",
    "            shape = (batch_size, vae.encoded_dim, image_size, image_size)\n",
    "\n",
    "            lowres_cond_img = maybe(vae.encode)(lowres_cond_img)\n",
    "\n",
    "            # denoising loop for image\n",
    "\n",
    "            img = self.p_sample_loop(\n",
    "                unet,\n",
    "                shape,\n",
    "                image_embed = image_embed,\n",
    "                text_encodings = text_encodings,\n",
    "                cond_scale = unet_cond_scale,\n",
    "                predict_x_start = predict_x_start,\n",
    "                learned_variance = learned_variance,\n",
    "                clip_denoised = not is_latent_diffusion,\n",
    "                lowres_cond_img = lowres_cond_img,\n",
    "                lowres_noise_level = lowres_noise_level,\n",
    "                is_latent_diffusion = is_latent_diffusion,\n",
    "                noise_scheduler = noise_scheduler,\n",
    "                timesteps = sample_timesteps,\n",
    "                inpaint_image = inpaint_image,\n",
    "                inpaint_mask = inpaint_mask,\n",
    "                inpaint_resample_times = inpaint_resample_times\n",
    "            )\n",
    "\n",
    "            img = vae.decode(img)\n",
    "\n",
    "        if exists(stop_at_unet_number) and stop_at_unet_number == unet_number:\n",
    "            break\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94cfab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.model_manager.decoder_info.model.sample_timesteps = (None, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95a3cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(pred, gt):\n",
    "    # pred \\in [0, 1]\n",
    "    pred_int = pred * 255\n",
    "    gt = gt * 255\n",
    "    pred_int = torch.round(pred_int)\n",
    "    gt = torch.round(gt)\n",
    "    return 20 * torch.log10(255 / torch.sqrt(F.mse_loss(pred_int, gt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c1cc3",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60d21913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79b6cf0f5304f1eb76fe234f9b44dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b18edf9a3f4c419a92aa8d6d333a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aadfba42a1bc4de7ba844c2cf85bb7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6df3a54ae74ad0a2929ffc7582eae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec0bafbcab243cb80bcfa8562a769f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15f0a27905e465482ba2486141a5f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d3469a53644c25bb48e80df2242b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0680c281354249a789e9eb58c4e65c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca648455e04b4ddf9dc8f13744325fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0338312f64cb438e9ef5953a884c7661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e411be96b4d451ab0aace85aa3e1d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f5107fe158409188a15576529cc0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60050152e16d48c2b8e8894afd86cc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a518a05a524011a0c296078593d6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b87d02e14643dea3e20ee874df04f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image = banana.jpg\n",
      "32.353666305541992\n",
      "\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60a557f14544f3a913b75fcf256c859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaa39adc44144dc92e2e5b369c865ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dbd25b7ec443d58f211eb48f8a5539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31d485f94f241509e642d94bba19314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d033698d09bc400981304b7a87d88fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25948b138bb145068feec6f5d9544f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c589792abead463bbc0d40640dea0a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f55a3f981e405bad2f2bba03e3588d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788445d3ac66492ba5ab18b6698f46d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77692d9d55c47d780b750de96acb99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acd3c0a982d4a6a8827818c34ca7b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0676f8e71c5b4e859c4dfcc149d2ae06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe2e3099fd0416abfc4407348ee8eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f6f9f85f02402a89f66d11b0741e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b3be23cb2e4e30a4ed876ee704549b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image = cat.jpg\n",
      "28.388410393013847\n",
      "\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b4060d1439426db586c564df84b2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d46c50139a645b3ac0e0705b8e77ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb9cbce02574464adc3aee1d06dc5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614d8fc339d1477489deb8668715f005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2edfdf8666f42debd68746ee40410fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcc57fb56724ec2b5e2def846d33254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67824d29c4ff4c9d866da9f122fb4669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3da310fa014dd29a93322bf7399bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee938f90bee424282d3542a74eb982a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46465c4df7674a86aae8d17b8098d030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86edb1d8c51d452fbb88ef1c8db8c47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188176375f36409683df1fd5876e3848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf35417c38d46f28bda9882479e2455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16994990bd3646bda94f2fd6ff16df74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b346c8c893485b9f9b1a7b1afb67f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image = elephant.jpg\n",
      "31.39283402941229\n",
      "\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743c276355574a35b568aea334f75114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59e776695f9483da6da82c3d16d121d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0b9a5bda444f6fa3836ff5e0c848b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c35c9145f224016b1ee8c7ba96aa3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd47c4bb71641fd9755ae0ad008b892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30317fc6d0064c6a8127b8b683ec51f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6fce35f497b44b983e6b3e4c2b3152a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99924ae42a5541caa81e3ea8b869c44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113eea2728d64028888dae2d009fdb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5530cb1e72044b30ada2201f30828e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22fa8d5079f446fad107f48e4e50ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94199f28952742c7ae5ece822f509069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5e72ee1a2042598f95a0dd0e4599df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73212cd59d14234b5c5f36b5c675458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da54ef3c30c4d399a5d1f1e863e8c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image = pizza.jpg\n",
      "29.120374890028384\n",
      "\n",
      "---------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd737898e4b14ad1902e128966ade2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4355859bd6a24275a939444333203259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994ef3abf0614abb8ca2d239e806ea6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a741bdc559534ddf935d6ca4539fc4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1def95a6458344ff9be1c39d363c2833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746b95eff04c49a2a353fdb1aa088748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c22f78f893e4b48a4eb8f1d2a0d4f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4035f804fb460c80fc06b0e51095ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ca8f50692d4a7481297edb3f5191f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2cd88032474808987341d51ef0bbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63308af7ab841579947d25a23665ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4244732fb249a9b6cf75bba9a6a1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d96959fc46491284d660272d1c6823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c6989aaa404990be8a2057856eba7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bded56bfd8b4474a504452d2e26221b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image = tie.jpg\n",
      "29.001123424938838\n",
      "\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = CocoDataset(\n",
    "    im_dir=\"images/\",\n",
    "    caption_dir=\"captions/\"\n",
    ")\n",
    "\n",
    "psnrs = []\n",
    "\n",
    "for source_image_i in range(len(dataset)):\n",
    "    (source_image_name, source_image, source_captions) = dataset[source_image_i]\n",
    "    max_psnr = 0\n",
    "    for text_str_i, text_str in enumerate(source_captions):\n",
    "        text = [text_str]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_embedding_map = inference._sample_prior(text)\n",
    "            image_embedding = image_embedding_map[0][0].unsqueeze(0)\n",
    "            source_image_small_64 = F.interpolate(source_image.unsqueeze(0), size=(64, 64))\n",
    "        source_image_small_256 = F.interpolate(source_image_small_64, size=(256, 256))\n",
    "        # normalize\n",
    "#         source_image_small_64 = source_image_small_64 * 2 - 1\n",
    "#         source_image_small_256 = source_image_small_256 * 2 - 1\n",
    "\n",
    "        #source_image_small_64.shape, source_image_small_256.shape\n",
    "\n",
    "        inference.model_manager.decoder_info.model.cuda()\n",
    "\n",
    "        source_image_small_256 = source_image_small_256.cuda()\n",
    "        with torch.no_grad():\n",
    "            text_encodings = inference._encode_text(text).cuda()\n",
    "        image_embed = image_embedding.cuda()\n",
    "        source_image_small_64 = source_image_small_64.cuda()\n",
    "        source_image = source_image.cuda()\n",
    "\n",
    "        text_encodings.requires_grad = True\n",
    "        image_embed.requires_grad = True\n",
    "\n",
    "        source_image_small_64.requires_grad = True\n",
    "        source_image_small_256.requires_grad = True\n",
    "        source_image.requires_grad = False\n",
    "\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            source_image_small_64, source_image_small_256, text_encodings, image_embed\n",
    "        ], lr = 1.0)\n",
    "        n_iters = 2\n",
    "        scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.5, total_iters=n_iters)\n",
    "        \n",
    "        for i in range(n_iters - 1):\n",
    "            inference.model_manager.decoder_info.model.train()\n",
    "            optimizer.zero_grad()\n",
    "            res = my_sample(\n",
    "                self=inference.model_manager.decoder_info.model,\n",
    "                lowres_cond_img=source_image_small_256,\n",
    "                image_embed = image_embed,\n",
    "                text_encodings = text_encodings,\n",
    "                image=source_image_small_64,\n",
    "                start_at_unet_number = 2,\n",
    "            )\n",
    "            res.retain_grad()\n",
    "            decoded_coco_image = res.squeeze(0)\n",
    "            loss = F.mse_loss(decoded_coco_image, source_image)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            inference.model_manager.decoder_info.model.eval()\n",
    "            with torch.no_grad():\n",
    "                max_psnr = max(psnr(decoded_coco_image, source_image).item(), max_psnr)\n",
    "    print(f\"image = {source_image_name}\")\n",
    "    print(max_psnr)\n",
    "    print(\"\\n---------------------------\\n\")\n",
    "    psnrs.append(max_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5949edc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.051281808587067\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.mean(psnrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834be8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
